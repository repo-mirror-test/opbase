/**
 * Copyright (c) 2025 Huawei Technologies Co., Ltd.
 * This program is free software, you can redistribute it and/or modify it under the terms and conditions of
 * CANN Open Software License Agreement Version 2.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */
#include "individual_op_api.h"
#include <mutex>
#include <thread>
#include <atomic>
#include "utils/indv_base.h"
#include "utils/indv_debug_assert.h"
#include "utils/indv_lib_wrapper.h"
#include "utils/thread_var_container.h"
#include "executor/indv_executor.h"
#include "executor/indv_tilingcontext_builder.h"
#include "executor/indv_bininfo.h"
#include "executor/indv_args_pool.h"
#include "profiling/prof_api.h"
#include "aclnn/aclnn_base.h"
#include "thread_local_context.h"
#include "opdev/platform.h"

void NnopbaseOpLogE(const aclnnStatus code, const NnopbaseChar *const expr)
{
    OP_LOGE(code, "Check %s failed", expr);
}
using namespace op::internal;

#ifdef __cplusplus
extern "C" {
#endif

NnopbaseExecutorSpaceSet g_nnopbaseSpaceSet;
static std::mutex g_nnopbaseInitMtx;

aclnnStatus NnopbaseInit()
{
    static bool isInit = false;
    if (isInit) {
        return OK;
    }
    OP_LOGI("NnopbaseInit Start.");
    if (gBinCollecter == nullptr) {
        auto binCollecter = std::make_unique<NnopbaseBinCollecter>();
        NNOPBASE_ASSERT_NOTNULL_RETVAL(binCollecter);
        NNOPBASE_ASSERT_OK_RETVAL(NnopbaseCollecterInit(binCollecter.get()));
        NNOPBASE_ASSERT_OK_RETVAL(NnopbaseCollecterWork(binCollecter.get()));
        gBinCollecter = binCollecter.release();
    }
    NnopbaseExecutorSpaceSetInit(&g_nnopbaseSpaceSet);
    NNOPBASE_ASSERT_OK_RETVAL(NnopbaseExecutorSetGlobalConfig());
    isInit = true;
    OP_LOGI("NnopbaseInit end");
    return OK;
}

void NnopbaseReloadStaticBinJsonInfos(void)
{
    OP_LOGI("NnopbaseReloadStaticBinJsonInfos Start");
    NnopbaseExecutorClearSet(&g_nnopbaseSpaceSet);
    auto ret = NnopbaseRefreshStaticKernelInfos(gBinCollecter);
    if (ret != OK) {
        OP_LOGW("Reload static kernel informations failed.");
    } else {
        OP_LOGI("Reload static kernel informations success.");
    }
    nnopbase::ArgsPool::GetInstance().Finalize();
    OP_LOGI("NnopbaseReloadStaticBinJsonInfos end");
}

aclnnStatus NnopbaseCreateExecutorSpace(void **space)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(space);
    const std::lock_guard<std::mutex> lock(g_nnopbaseInitMtx);
    NNOPBASE_ASSERT_RTOK_RETVAL(NnopbaseInit());
    if (*space == nullptr) {
        NnopbaseExecutorSpace *executorSpace = new(std::nothrow) NnopbaseExecutorSpace;
        NNOPBASE_ASSERT_NOTNULL_RETVAL(executorSpace);
        *space = executorSpace;
        NnopbaseExecutorAddSpaceToSet(&g_nnopbaseSpaceSet, executorSpace);
    }
    return OK;
}

void* NnopbaseGetExecutor(void *space, const NnopbaseChar *opType, NnopbaseChar *inputsDesc, uint32_t inputNum,
                          NnopbaseChar *outputsDesc, uint32_t outputNum, NnopbaseChar *attrsDesc, uint32_t attrsNum)
{
    op::internal::GetThreadLocalContext().logInfo_.l2ApiName = opType;
    NnopbaseExecutorSpace *executorSpace = (NnopbaseExecutorSpace *) space;
    if (executorSpace == nullptr) {
        return nullptr;
    }

    const std::lock_guard<std::mutex> lock(executorSpace->spaceMtx);
    // 同一个opType可以对应多个executor
    for (auto executor : executorSpace->executors) {
        if ((executor != nullptr) && (!executor->isWork)) {
            executor->isWork = true;
            executor->poolIndex = op::internal::GetThreadLocalContext().poolIndex_;
            OP_LOGI("Get op %s space %p executor addr %p.", opType, space, executor);
            RecordNnopbaseTime(executor, NnopbaseTimeIdx::kAferCreateExecutor);
            // 留出optype的偏移量后续生成key的时候用
            executor->ownArgs.keyLen = strlen(executor->opType);
            executor->ownArgs.remainKeyLen = NNOPBASE_MAX_ARGS_KEY_LEN - strlen(executor->opType);
            return executor;
        }
    }

    NnopbaseExecutor *executor = new(std::nothrow) NnopbaseExecutor;
    if (executor != nullptr) {
        aclnnStatus ret =
            NnopbaseExecutorInit(executor, {inputsDesc, inputNum, outputsDesc, outputNum, attrsDesc, attrsNum});
        if (ret == OK) {
            NnopbaseExecutorSetCollecter(executor, gBinCollecter);
            executor->space = (NnopbaseExecutorSpace*)space;
            ret = NnopbaseExecutorSetRegInfo(executor, opType);
        }
        if (ret != OK) {
            NnopbaseExecutorDeInit(executor);
            delete executor;
            executor = nullptr;
        }
    }
    if (executor != nullptr) {
        executor->isWork = true;
        executor->poolIndex = op::internal::GetThreadLocalContext().poolIndex_;
        executorSpace->executors.push_back(executor);
        RecordNnopbaseTime(executor, NnopbaseTimeIdx::kAferCreateExecutor);
        // 留出optype的偏移量后续生成key的时候用
        executor->ownArgs.keyLen = strlen(executor->opType);
        executor->ownArgs.remainKeyLen = NNOPBASE_MAX_ARGS_KEY_LEN - strlen(executor->opType);
    }
    OP_LOGI("Get op %s space %p executor addr %p.", opType, space, executor);
    return executor;
}

aclnnStatus NnopbaseRunForWorkspace(void *executor, uint64_t *workspaceLen)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(workspaceLen);
    return NnopbaseExecutorRunForWorkspace((NnopbaseExecutor *)executor, workspaceLen);
}

aclnnStatus NnopbaseRunWithWorkspace(void *executor, aclrtStream stream, void *workspace, uint64_t workspaceLen)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    if (workspaceLen > 0U) {
        NNOPBASE_ASSERT_NOTNULL_RETVAL(workspace);
    }

    NnopbaseExecutor *nnopExecutor = PtrCastTo<NnopbaseExecutor>(executor);
    RecordNnopbaseTime(nnopExecutor, NnopbaseTimeIdx::kRunWithWsStart);
    op::internal::GetThreadLocalContext().logInfo_.l2ApiName = nnopExecutor->opType;
    OP_LOGI("Run op %s with workspace len %lu bytes, executor addr %p, executor workspace len %lu bytes.",
            nnopExecutor->opType, workspaceLen, nnopExecutor, nnopExecutor->workspaces.length);
    NNOPBASE_ASSERT_TRUE_RETVAL(workspaceLen >= nnopExecutor->workspaces.length);
    return NnopbaseExecutorRunWithWorkspace(nnopExecutor, stream, workspace, workspaceLen);
}
aclnnStatus NnopbaseAddInput(void *executor, const aclTensor *tensor, const uint32_t index)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NnopbaseExecutor *nnopExecutor = PtrCastTo<NnopbaseExecutor>(executor);
    const auto tensors = &nnopExecutor->ownArgs.inputs;
    if (NnopbasIsEnableNewCache(nnopExecutor)) {
        tensors->paramDescs.instances[index].tensor = tensor;
        NnopbaseGenTensorKey(&nnopExecutor->ownArgs, tensor);
        return OK;
    } else {
        NNOPBASE_ASSERT_OK_RETVAL(NnopbaseExecutorUpdateTensorsIndex(tensors, index));
        return NnopbaseExecutorAddTensor(nnopExecutor, tensor, index, true, false);
    }
}

aclnnStatus NnopbaseAddIgnoreContinuesInput(void *executor, const aclTensor *tensor, const uint32_t index)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NnopbaseExecutor *nnopExecutor = PtrCastTo<NnopbaseExecutor>(executor);
    const auto tensors = &nnopExecutor->ownArgs.inputs;
    if (NnopbasIsEnableNewCache(nnopExecutor)) {
        tensors->paramDescs.instances[index].ignoreCont = true;
        tensors->paramDescs.instances[index].tensor = tensor;
        NnopbaseGenTensorKey(&nnopExecutor->ownArgs, tensor);
        return OK;
    } else {
        NNOPBASE_ASSERT_OK_RETVAL(NnopbaseExecutorUpdateTensorsIndex(tensors, index));
        return NnopbaseExecutorAddTensor(nnopExecutor, tensor, index, true, true);
    }
}

aclnnStatus NnopbaseAddIntArrayInput(void *executor, const aclIntArray *array, const uint32_t index)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NnopbaseExecutor *nnopExecutor = PtrCastTo<NnopbaseExecutor>(executor);
    const auto tensors = &nnopExecutor->ownArgs.inputs;
    if (NnopbasIsEnableNewCache(nnopExecutor)) {
        tensors->paramDescs.instances[index].intArray = array;
        auto args = &nnopExecutor->ownArgs;
        if (array != nullptr) {
            NnopbaseExecutorGenValueDependTensorKey(args,
            array->GetData(),
            array->Size(),
            array->Size() * sizeof(int64_t),
            ge::DataType::DT_INT64);
        } else {
            NnopbaseGenPlaceHolderKey(args, PtrCastTo<NnopbaseUChar>(args->inputKey.data() + args->keyLen));
        }
        return OK;
    } else {
        NNOPBASE_ASSERT_OK_RETVAL(NnopbaseExecutorUpdateTensorsIndex(tensors, index));
        return nnopbase::NnopbaseExecutorAddArrayInput<aclIntArray>(tensors, array, index);
    }
}

aclnnStatus NnopbaseAddBoolArrayInput(void *executor, const aclBoolArray *array, const uint32_t index)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NnopbaseExecutor *nnopExecutor = PtrCastTo<NnopbaseExecutor>(executor);
    const auto tensors = &nnopExecutor->ownArgs.inputs;
    if (NnopbasIsEnableNewCache(nnopExecutor)) {
        tensors->paramDescs.instances[index].boolArray = array;
        auto args = &nnopExecutor->ownArgs;
        if (array != nullptr) {
            NnopbaseExecutorGenValueDependTensorKey(args,
            array->GetData(),
            array->Size(),
            array->Size() * sizeof(bool),
            ge::DataType::DT_BOOL);
        } else {
            NnopbaseGenPlaceHolderKey(args, PtrCastTo<NnopbaseUChar>(args->inputKey.data() + args->keyLen));
        }
        return OK;
    } else {
        NNOPBASE_ASSERT_OK_RETVAL(NnopbaseExecutorUpdateTensorsIndex(tensors, index));
        return nnopbase::NnopbaseExecutorAddArrayInput<aclBoolArray>(tensors, array, index);
    }
}

aclnnStatus NnopbaseAddFloatArrayInput(void *executor, const aclFloatArray *array, const uint32_t index)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NnopbaseExecutor *nnopExecutor = PtrCastTo<NnopbaseExecutor>(executor);
    const auto tensors = &nnopExecutor->ownArgs.inputs;
    if (NnopbasIsEnableNewCache(nnopExecutor)) {
        tensors->paramDescs.instances[index].floatArray = array;
        auto args = &nnopExecutor->ownArgs;
        if (array != nullptr) {
            NnopbaseExecutorGenValueDependTensorKey(args,
            array->GetData(),
            array->Size(),
            array->Size() * sizeof(float),
            ge::DataType::DT_FLOAT);
        } else {
            NnopbaseGenPlaceHolderKey(args, PtrCastTo<NnopbaseUChar>(args->inputKey.data() + args->keyLen));
        }
        return OK;
    } else {
        NNOPBASE_ASSERT_OK_RETVAL(NnopbaseExecutorUpdateTensorsIndex(tensors, index));
        return nnopbase::NnopbaseExecutorAddArrayInput<aclFloatArray>(tensors, array, index);
    }
}

aclnnStatus NnopbaseAddDynamicInput(void *executor, const aclTensorList *tensorList, const uint32_t index)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NnopbaseExecutor *nnopExecutor = PtrCastTo<NnopbaseExecutor>(executor);
    const auto tensors = &nnopExecutor->ownArgs.inputs;
    if (NnopbasIsEnableNewCache(nnopExecutor)) {
        tensors->paramDescs.instances[index].tensorList = tensorList;
        NnopbaseExecutorGenTensorListKey(&nnopExecutor->ownArgs, tensorList);
        return OK;
    } else {
        return NnopbaseExecutorAddDynamicTensors(nnopExecutor, tensorList, index, true);
    }
}

aclnnStatus NnopbaseAddOutput(void *executor, const aclTensor *tensor, const uint32_t index)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NnopbaseExecutor *nnopExecutor = PtrCastTo<NnopbaseExecutor>(executor);
    const auto tensors = &nnopExecutor->ownArgs.outputs;
    if (NnopbasIsEnableNewCache(nnopExecutor)) {
        tensors->paramDescs.instances[index].tensor = tensor;
        auto args = &nnopExecutor->ownArgs;
        // 输出和属性中间要用占位符隔开
        if (index == 0) {
            NnopbaseGenPlaceHolderKey(args, PtrCastTo<NnopbaseUChar>(args->inputKey.data() + args->keyLen));
        }
        NnopbaseGenTensorKey(args, tensor);
        return OK;
    } else {
        NNOPBASE_ASSERT_OK_RETVAL(NnopbaseExecutorUpdateTensorsIndex(tensors, index));
        return NnopbaseExecutorAddTensor(nnopExecutor, tensor, index, false, false);
    }
}

aclnnStatus NnopbaseAddOutputShapeDependTensor(void *executor, aclTensor *tensor, const uint32_t index)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NnopbaseTensors *tensors = &(((NnopbaseExecutor *)executor)->ownArgs.outputs);
    tensors->outPutShapeSize += sizeof(uint64_t) * 9U; // 9 表示1个count和8个dim
    tensors->outPutShapeMap[index] = tensor; // 覆盖刷新tensor地址
    OP_LOGI("Add output shape depend tensor [%u] successfully, addr is %p.", index, tensor);
    return NnopbaseAddOutput(executor, tensor, index);
}

aclnnStatus NnopbaseAddDynamicOutput(void *executor, const aclTensorList *tensorList, const uint32_t index)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NnopbaseExecutor *nnopExecutor = PtrCastTo<NnopbaseExecutor>(executor);
    const auto tensors = &nnopExecutor->ownArgs.outputs;
    if (NnopbasIsEnableNewCache(nnopExecutor)) {
        tensors->paramDescs.instances[index].tensorList = tensorList;
        auto args = &nnopExecutor->ownArgs;
        if (index == 0) {
            NnopbaseGenPlaceHolderKey(args, PtrCastTo<NnopbaseUChar>(args->inputKey.data() + args->keyLen));
        }
        NnopbaseExecutorGenTensorListKey(args, tensorList);
        return OK;
    } else {
        return NnopbaseExecutorAddDynamicTensors(nnopExecutor, tensorList, index, false);
    }
}

aclnnStatus NnopbaseAddParamName(void *executor, const uint32_t index, const char *name, const bool isInput)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(name);

    NnopbaseTensors *tensors = nullptr;
    if (isInput) {
        tensors = &(((NnopbaseExecutor *)executor)->ownArgs.inputs);
    } else {
        tensors = &(((NnopbaseExecutor *)executor)->ownArgs.outputs);
    }

    CHECK_COND(index < tensors->paramDescs.count,
        ACLNN_ERR_PARAM_INVALID, "Tensor index [%zu] is greater than or equal to IrTensor num: %d",
        index, tensors->paramDescs.count);
    tensors->paramDescs.instances[index].name = name;
    return OK;
}

aclnnStatus NnopbaseAddAttr(void *executor, void* attrAddr, const size_t attrLen, const size_t index)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(attrAddr);
    OP_LOGI("NnopbaseAdd Attr addr %p, attrLen %zu, index %zu.", attrAddr, attrLen, index);
    return NnopbaseExecutorAddAttr((NnopbaseExecutor *)executor, attrAddr, attrLen, index, 0U, kNnopbaseAttrEnd);
}

aclnnStatus NnopbaseAddAttrWithDtype(void *executor, void* attrAddr, const size_t attrLen, const size_t index,
                                     const NnopbaseAttrDtype dtype)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(attrAddr);
    OP_LOGI("NnopbaseAdd %s Attr addr %p, attrLen %zu, index %zu.", nnopbase::ToStr(dtype).c_str(),
            attrAddr, attrLen, index);
    return NnopbaseExecutorAddAttr((NnopbaseExecutor *)executor, attrAddr, attrLen, index, 0U, dtype);
}

aclnnStatus NnopbaseAddIntArrayAttr(void *executor, const aclIntArray* array, const size_t index)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(array);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    OP_LOGI("NnopbaseAddIntArrayAttr index %zu, size %lu.", index, array->Size());
    return NnopbaseExecutorAddAttr((NnopbaseExecutor *)executor, const_cast<void *>((const void*)array->GetData()),
                                   array->Size() * sizeof(int64_t), index, sizeof(int64_t), kNnopbaseInt);
}

aclnnStatus NnopbaseAddBoolArrayAttr(void *executor, const aclBoolArray* array, const size_t index)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(array);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    OP_LOGI("NnopbaseAddBoolArrayAttr index %zu, size %lu.", index, array->Size());
    return NnopbaseExecutorAddAttr((NnopbaseExecutor *)executor, const_cast<void *>((const void*)array->GetData()),
                                   array->Size() * sizeof(bool), index, sizeof(bool), kNnopbaseBool);
}

aclnnStatus NnopbaseAddFloatArrayAttr(void *executor, const aclFloatArray* array, const size_t index)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(array);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    OP_LOGI("NnopbaseAddFloatArrayAttr index %zu, size %lu.", index, array->Size());
    return NnopbaseExecutorAddAttr((NnopbaseExecutor *)executor, const_cast<void *>((const void*)array->GetData()),
                                   array->Size() * sizeof(float), index, sizeof(float), kNnopbaseFloat);
}

aclnnStatus NnopbaseAddArrayAttr(void *executor, void *array, const size_t len, const size_t elementSize,
                                 const size_t index)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(array);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    OP_LOGI("NnopbaseAdd ArrayAttr index %zu, arrayLen %zu, elementSize %zu.", index, len, elementSize);
    return NnopbaseExecutorAddAttr((NnopbaseExecutor *)executor, array, len * elementSize, index, elementSize,
                                   kNnopbaseAttrEnd);
}

aclnnStatus NnopbaseAddArrayAttrWithDtype(void *executor, void *array, const size_t len, const size_t elementSize,
                                          const size_t index, const NnopbaseAttrDtype dtype)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(array);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    OP_LOGI("NnopbaseAdd %s ArrayAttr index %zu, arrayLen %zu, elementSize %zu.", nnopbase::ToStr(dtype).c_str(),
            index, len, elementSize);
    return NnopbaseExecutorAddAttr((NnopbaseExecutor *)executor, array, len * elementSize, index, elementSize, dtype);
}

aclnnStatus NnopbaseGetAttrAddr(void *executor, const size_t index, void **attrAddr, size_t *attrLen)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(attrAddr);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(attrLen);
    aclnnStatus ret;
    NnopbaseAttrAddr *attr = nullptr;
    ret = NnopbaseExecutorGetAttr((NnopbaseExecutor *)executor, index, &attr);
    if (attr != nullptr) {
        *attrAddr = attr->addr;
        *attrLen = attr->size;
    }
    return ret;
}

void NnopbaseSetUserHandle(void *executor, void *handle)
{
    NNOPBASE_ASSERT_NOTNULL(executor);
    ((NnopbaseExecutor *)executor)->userHandle = handle;
}

void *NnopbaseGetUserHandle(void *executor)
{
    if (executor == nullptr) {
        OP_LOGE(ACLNN_ERR_PARAM_NULLPTR, "NnopbaseGetUserHandle failed, input executor is null.");
        return nullptr;
    }
    return ((NnopbaseExecutor *)executor)->userHandle;
}

void NnopbaseGetTilingData(void *executor, void **tilingData, uint64_t *dataLen)
{
    NNOPBASE_ASSERT_NOTNULL(executor);
    NNOPBASE_ASSERT_NOTNULL(tilingData);
    NNOPBASE_ASSERT_NOTNULL(dataLen);
    NnopbaseExecutor *nnopExecutor = (NnopbaseExecutor *)executor;
    if (nnopExecutor->hasTiling && ((NnopbaseTilingData *)nnopExecutor->args != nullptr)) {
        auto tilingDataPtr = (NnopbaseTilingData *)nnopExecutor->args->tilingInfo.tilingData;
        if (tilingDataPtr != nullptr) {
            *tilingData = (void *)tilingDataPtr->GetData();
            *dataLen = (uint64_t)tilingDataPtr->GetDataSize();
            return;
        }
    }

    *tilingData = nullptr;
    *dataLen = 0U;
}

void NnopbaseGetInputTensorAddr(void *executor, size_t index, void **addr)
{
    NNOPBASE_ASSERT_NOTNULL(executor);
    NNOPBASE_ASSERT_NOTNULL(addr);
    auto tensors = &(((NnopbaseExecutor *)executor)->args->inputs);
    NNOPBASE_ASSERT_TRUE(index < tensors->arrayLen);
    *addr = tensors->extTensors[index].rt2Tensor.GetAddr();
}

void NnopbaseGetOutputTensorAddr(void *executor, size_t index, void **addr)
{
    NNOPBASE_ASSERT_NOTNULL(executor);
    NNOPBASE_ASSERT_NOTNULL(addr);
    auto tensors = &(((NnopbaseExecutor *)executor)->args->outputs);
    NNOPBASE_ASSERT_TRUE(index < tensors->arrayLen);
    *addr = tensors->extTensors[index].rt2Tensor.GetAddr();
}

aclnnStatus NnopbaseGetInputTensorCount(const void *const executor, const size_t irIndex, uint32_t *const count)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(count);

    const auto &tensors = (PtrCastTo<NnopbaseExecutor>(executor))->args->inputs;
    CHECK_COND((irIndex < tensors.paramDescs.count), ACLNN_ERR_PARAM_INVALID, "Get input tensor count "
               "failed. irIndex[%zu] is out of input num[%u].", irIndex, tensors.paramDescs.count);
    *count = tensors.paramDescs.instances[irIndex].num;
 
    return OK;
}
 
aclnnStatus NnopbaseGetOutputTensorCount(const void *const executor, const size_t irIndex, uint32_t *const count)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(count);

    const auto &tensors = (PtrCastTo<NnopbaseExecutor>(executor))->args->outputs;
    CHECK_COND((irIndex < tensors.paramDescs.count), ACLNN_ERR_PARAM_INVALID, "Get output tensor count "
               "failed. irIndex[%zu] is out of output num[%u].", irIndex, tensors.paramDescs.count);
    *count = tensors.paramDescs.instances[irIndex].num;
 
    return OK;
}

static aclnnStatus NnopbaseGetDynamicTensorAddrs(const NnopbaseTensors &tensors,
                                                 const size_t irIndex,
                                                 void **const addrs,
                                                 const size_t addrSize,
                                                 uint32_t *const count)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(addrs);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(count);
    CHECK_COND((irIndex < tensors.paramDescs.count), ACLNN_ERR_PARAM_INVALID, "Get tensor addrs failed. "
               "irIndex[%zu] is out of input or output num[%u].", irIndex, tensors.paramDescs.count);
    CHECK_COND(tensors.paramDescs.instances[irIndex].isDynamic, ACLNN_ERR_PARAM_INVALID,
               "Get tensor addrs failed. tensor[%zu] must is dynamic. isDynamic = %d.",
               irIndex, tensors.paramDescs.instances[irIndex].isDynamic);

    uint32_t num = tensors.paramDescs.instances[irIndex].num;
    OP_LOGI("NnopbaseGetDynamicTensorAddrs debug info, irIndex = %zu, "
            "addrSize = %zu bytes, tensors num = %u.", irIndex, addrSize, num);
    if (addrSize < num) {
        num = static_cast<uint32_t>(addrSize);
    }

    const uint32_t startIndex = tensors.paramDescs.instances[irIndex].startIndex;
    for (uint32_t idx = 0U; idx < num; idx++) {
        addrs[idx] = tensors.extTensors[startIndex + idx].rt2Tensor.GetTensorData().GetAddr();
    }

    *count = num;
    return OK;
}

aclnnStatus NnopbaseGetDynamicInputTensorAddrs(const void *const executor, const size_t irIndex, void **const addrs,
                                               const size_t addrSize, uint32_t *const count)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    return NnopbaseGetDynamicTensorAddrs(
        (PtrCastTo<NnopbaseExecutor>(executor))->args->inputs, irIndex, addrs, addrSize, count);
}

aclnnStatus NnopbaseGetDynamicOutputTensorAddrs(const void *const executor, const size_t irIndex, void **const addrs,
                                                const size_t addrSize, uint32_t *const count)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    return NnopbaseGetDynamicTensorAddrs(
        (PtrCastTo<NnopbaseExecutor>(executor))->args->outputs, irIndex, addrs, addrSize, count);
}

aclnnStatus NnopbaseSetInputTensorAddr(void *executor, const size_t index, const void *const addr)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);

    NnopbaseExecutor *nnopExecutor = PtrCastTo<NnopbaseExecutor>(executor);
    auto &tensors = nnopExecutor->args->inputs;
    CHECK_COND((index < tensors.num), ACLNN_ERR_PARAM_INVALID, "Set input tensor addrs failed. "
               "index[%zu] is out of tensor num[%u].", index, tensors.num);
    CHECK_COND(!tensors.extTensors[index].isNull, ACLNN_ERR_PARAM_INVALID, "Set input tensor addrs failed. "
               "The source address of the tensor is null. tensor index = %zu.", index);
    NNOPBASE_ASSERT_OK_RETVAL(tensors.extTensors[index].rt2Tensor.MutableTensorData().SetAddr(addr, nullptr));
    return NnopbaseSetRefTensorAddr(nnopExecutor,
        index,
        addr,
        tensors.paramDescs.instances,
        nnopExecutor->args->outputs.paramDescs.instances);
}

aclnnStatus NnopbaseSetOutputTensorAddr(void *executor, const size_t index, const void *const addr)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);

    NnopbaseExecutor *nnopExecutor = PtrCastTo<NnopbaseExecutor>(executor);
    auto &tensors = nnopExecutor->args->outputs;
    CHECK_COND((index < tensors.num), ACLNN_ERR_PARAM_INVALID, "Set output tensor addrs failed. "
               "index[%zu] is out of tensor num[%u].", index, tensors.num);
    CHECK_COND(!tensors.extTensors[index].isNull, ACLNN_ERR_PARAM_INVALID, "Set output tensor addrs failed. "
               "The source address of the tensor is null. tensor index = %zu.", index);
    NNOPBASE_ASSERT_OK_RETVAL(tensors.extTensors[index].rt2Tensor.MutableTensorData().SetAddr(addr, nullptr));
    return OK;
}

aclnnStatus NnopbaseSetDynamicInputTensorAddr(void *executor, size_t irIndex, const size_t relativeIndex,
                                              const void *const addr)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);

    NnopbaseExecutor *nnopExecutor = PtrCastTo<NnopbaseExecutor>(executor);
    auto &tensors = nnopExecutor->args->inputs;
    CHECK_COND((irIndex < tensors.paramDescs.count), ACLNN_ERR_PARAM_INVALID, "Set intput tensor addrs failed. "
               "index[%zu] is out of input num[%u].", irIndex, tensors.paramDescs.count);
    CHECK_COND((relativeIndex < tensors.paramDescs.instances[irIndex].num), ACLNN_ERR_PARAM_INVALID,
                "Set input tensor addrs failed. tensor index[%zu] is out of tensor num[%u].",
                relativeIndex, tensors.paramDescs.instances[irIndex].num);

    const size_t index = static_cast<size_t>(tensors.paramDescs.instances[irIndex].startIndex) + relativeIndex;
    CHECK_COND(!tensors.extTensors[index].isNull, ACLNN_ERR_PARAM_INVALID, "Set input tensor addrs failed. "
               "The source address of the tensor is null. irIndex = %zu, relativeIndex = %zu, tensor index = %zu.",
               irIndex, relativeIndex, index);
    NNOPBASE_ASSERT_OK_RETVAL(tensors.extTensors[index].rt2Tensor.MutableTensorData().SetAddr(addr, nullptr));
    auto &inInstances = tensors.paramDescs.instances;
    if (inInstances[irIndex].refIdx != -1) {
        NnopbaseSetDynamicOutputTensorAddr(executor, inInstances[irIndex].refIdx, relativeIndex, addr);
    }
    return OK;
}

aclnnStatus NnopbaseSetDynamicOutputTensorAddr(void *executor, size_t irIndex, const size_t relativeIndex,
                                               const void *const addr)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);

    NnopbaseExecutor *nnopExecutor = PtrCastTo<NnopbaseExecutor>(executor);
    auto &tensors = nnopExecutor->args->outputs;
    CHECK_COND((irIndex < tensors.paramDescs.count), ACLNN_ERR_PARAM_INVALID, "Set output tensor addrs failed. "
               "index[%zu] is out of input num[%u].", irIndex, tensors.paramDescs.count);
    CHECK_COND((relativeIndex < tensors.paramDescs.instances[irIndex].num), ACLNN_ERR_PARAM_INVALID,
                "Set output tensor addrs failed. tensor index[%zu] is out of tensor num[%u].",
                relativeIndex, tensors.paramDescs.instances[irIndex].num);

    const size_t index = static_cast<size_t>(tensors.paramDescs.instances[irIndex].startIndex) + relativeIndex;
    CHECK_COND(!tensors.extTensors[index].isNull, ACLNN_ERR_PARAM_INVALID, "Set output tensor addrs failed. "
               "The source address of the tensor is null. irIndex = %zu, relativeIndex = %zu, tensor index = %zu.",
               irIndex, relativeIndex, index);
    NNOPBASE_ASSERT_OK_RETVAL(tensors.extTensors[index].rt2Tensor.MutableTensorData().SetAddr(addr, nullptr));
    return OK;
}

aclnnStatus NnopbaseDisableOptionalInput(void *executor, const size_t irIndex)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NnopbaseExecutor *nnopExecutor = PtrCastTo<NnopbaseExecutor>(executor);
    auto &tensors = nnopExecutor->args->inputs;
    CHECK_COND((irIndex < tensors.paramDescs.count), ACLNN_ERR_PARAM_INVALID, "Disable optional input failed. "
               "index[%zu] is out of input num[%u].", irIndex, tensors.paramDescs.count);
    tensors.paramDescs.instances[irIndex].isDisable = true;
    tensors.paramDescs.activeInputCount--;
    return OK;
}

uint64_t NnopbaseMsprofSysTime()
{
    if (op::internal::opProfilingSwitch.reportFlag ||
        op::internal::opProfilingSwitch.kernelLaunchFlag ||
        op::internal::opProfilingSwitch.additionInfoFlag ||
        op::internal::opProfilingSwitch.level2ProfilingFlag ||
        op::internal::opProfilingSwitch.timeStampFlag) {
            return MsprofSysCycleTime();
        }
    return 0U;
}

aclnnStatus NnopbaseAddTilingId(void *executor, NnopbaseDfxId *tilingId)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(tilingId);
    NnopbaseExecutorAddTilingId((NnopbaseExecutor *)executor, tilingId);
    return OK;
}

aclnnStatus NnopbaseAddSupportList(void *executor, OpSupportList *list,
                                   uint32_t *socSupportList, size_t socSupportListLen)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(list);
    NnopbaseExecutorAddSupportList((NnopbaseExecutor *)executor, list, socSupportList, socSupportListLen);
    return OK;
}

void NnopbaseAddOpTypeId(void *executor, const uint32_t opTypeId)
{
    NNOPBASE_ASSERT_NOTNULL(executor);
    NnopbaseExecutorAddOpTypeId((NnopbaseExecutor *)executor, opTypeId);
}

aclnnStatus NnopbaseGetUnContiguousTensors(void *executor, const aclTensorList **inTensors)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(inTensors);
    NnopbaseExecutorGetUnContiguousTensors((NnopbaseExecutor *)executor, inTensors);
    return OK;
}

aclnnStatus NnopbaseSetUnContExecutor(void *executor, aclOpExecutor *inExe, const size_t inWsSize)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NnopbaseExecutorSetUnContExecutor((NnopbaseExecutor *)executor, inExe, inWsSize);
    return OK;
}

aclnnStatus NnopbaseGetUnContExecutor(void *executor, aclOpExecutor **inExe, size_t *inWsSize)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(inExe);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(inWsSize);
    NnopbaseExecutorGetUnContExecutor((NnopbaseExecutor *)executor, inExe, inWsSize);
    return OK;
}

aclnnStatus NnopbaseGetRefUnContiguousTensors(void *executor, const aclTensorList **unContTensors,
                                              const aclTensorList **contTensors)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(unContTensors);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(contTensors);
    NnopbaseExecutorGetRefUnContiguousTensors((NnopbaseExecutor *)executor, unContTensors, contTensors);
    return OK;
}

aclnnStatus NnopbaseSetRef(void *executor, const size_t inputIrIdx, const size_t outputIrIdx)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    return NnopbaseExecutorSetRef((NnopbaseExecutor *)executor, inputIrIdx, outputIrIdx);
}

aclnnStatus NnopbaseSetViewCopyExecutor(void *executor, aclOpExecutor *exe)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NnopbaseExecutorSetViewCopyExecutor((NnopbaseExecutor *)executor, exe);
    return OK;
}

aclnnStatus NnopbaseGetViewCopyExecutor(void *executor, aclOpExecutor **exe)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(exe);
    NnopbaseExecutorGetViewCopyExecutor((NnopbaseExecutor *)executor, exe);
    return OK;
}

aclnnStatus NnopbaseReleaseRefContiguousTensors(void *executor, const aclTensorList **tensors)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(tensors);
    NnopbaseExecutorReleaseRefContiguousTensors((NnopbaseExecutor *)executor, tensors);
    return OK;
}

aclnnStatus NnopbaseAddScalarInput(void *executor, const aclScalar *scalar, const uint32_t index,
                                   const int32_t srcIndex, const ge::DataType dtype)
{
    OP_LOGD("NnopbaseAddScalarInput Start.");
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NnopbaseExecutor *nnopExecutor = PtrCastTo<NnopbaseExecutor>(executor);
    const auto tensors = &nnopExecutor->ownArgs.inputs;
    if (NnopbasIsEnableNewCache(nnopExecutor)) {
        tensors->paramDescs.instances[index].scalar = scalar;
        tensors->paramDescs.instances[index].scalarDtype = dtype;
        tensors->paramDescs.instances[index].srcIndex = srcIndex;
        NnopbaseExecutorGenScalarKey(nnopExecutor, scalar, index, srcIndex, dtype);
        return OK;
    } else {
        NNOPBASE_ASSERT_OK_RETVAL(NnopbaseExecutorUpdateTensorsIndex(tensors, index));
        return NnopbaseExecutorAddScalarInput(tensors, scalar, index, srcIndex, dtype);
    }
}

aclnnStatus NnopbaseAddScalarListInput(void *executor, const aclScalarList *scalarList, const uint32_t index,
                                       const int32_t srcIndex, const ge::DataType dtype)
{
    OP_LOGD("NnopbaseAddScalarListInput Start.");
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NnopbaseExecutor *nnopExecutor = PtrCastTo<NnopbaseExecutor>(executor);
    const auto tensors = &nnopExecutor->ownArgs.inputs;
    if (NnopbasIsEnableNewCache(nnopExecutor)) {
        tensors->paramDescs.instances[index].scalarList = scalarList;
        tensors->paramDescs.instances[index].scalarDtype = dtype;
        tensors->paramDescs.instances[index].srcIndex = srcIndex;
        NnopbaseExecutorGenScalarListKey(nnopExecutor, scalarList, index, srcIndex, dtype);
        return OK;
    } else {
        NNOPBASE_ASSERT_OK_RETVAL(NnopbaseExecutorUpdateTensorsIndex(tensors, index));
        return NnopbaseExecutorAddScalarListInput(tensors, scalarList, index, srcIndex, dtype);
    }
}

const NnopbaseChar *NnopbaseFindStaticKernel(const NnopbaseChar *opType,
                                             const aclTensor* tensors[],
                                             int64_t numTensors,
                                             [[maybe_unused]] const int64_t dynamicIndex[],
                                             [[maybe_unused]] const int64_t dynamicCount[],
                                             int64_t numDynamic,
                                             const NnopbaseAttrAddr* attrs[],
                                             int64_t numAttrs,
                                             int64_t implMode,
                                             int64_t deterMode,
                                             const int64_t valueDepend[],
                                             int64_t numValueDepend)
{
    {
        const std::lock_guard<std::mutex> lock(g_nnopbaseInitMtx);
        if (NnopbaseInit() != OK) {
            return nullptr;
        }
    }
    thread_local static NnopbaseUChar verbose[NNOPBASE_MAX_STATICKEY_LEN];
    NnopbaseUChar *verKey = verbose;
    NnopbaseStaticTensorNumInfo tensorNumInfo;
    tensorNumInfo.numTensors = numTensors;
    tensorNumInfo.numDynamic = numDynamic;
    tensorNumInfo.numAttrs = numAttrs;
    tensorNumInfo.numValueDepend = numValueDepend;
    NnopbaseRegInfoKey regInfoKey;

    regInfoKey.opType = std::string(opType);
    regInfoKey.hashKey =
        static_cast<uint64_t>(NnopbaseHashBinary((NnopbaseUChar *)regInfoKey.opType.c_str(), regInfoKey.opType.size()) %
                              NNOPBASE_NORM_MAX_BIN_BUCKETS);
    OP_LOGI("OpType is %s, hashkey is %lu.", regInfoKey.opType.c_str(), regInfoKey.hashKey);
    verKey = NnopbaseCollecterGenStaticKey(verKey, &regInfoKey, &tensorNumInfo, tensors,
                                           attrs, implMode, deterMode, valueDepend);
    return NnopbaseCollecterGetBinPath(regInfoKey.opType.c_str(), regInfoKey.hashKey, verbose,
                                       uint32_t(verKey - verbose));
}

aclnnStatus NnopbaseGetStreamAndEvent(const rtStream_t stream, rtStream_t *subStream,
    rtEvent_t *evtA, rtEvent_t *evtB, std::shared_ptr<std::mutex> &streamLckPtr)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(subStream);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(evtA);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(evtB);
    return NnopbaseExecutorGetStreamAndEvent(stream, subStream, evtA, evtB, streamLckPtr);
}

// mc2
aclnnStatus NnopbaseSetMc2(void *const executor)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    ((NnopbaseExecutor *)executor)->mc2OpCfg.isMc2 = true;
    auto socVersion = (static_cast<NnopbaseExecutor *>(executor))->collecter->socVersion;
    bool needLoadDavidHcclApi = false;
    if ((socVersion == OPS_SUBPATH_ASCEND910_95) || (socVersion == OPS_SUBPATH_ASCEND910_96)) {
        needLoadDavidHcclApi = true;
    }
    static const aclnnStatus ret = nnopbase::IndvHcclWrapper::GetInstance().IndvHcclWrapperInit("libhccl.so",
        needLoadDavidHcclApi);
    CHECK_COND((ret == OK), ret, "Nnopbase load hccl module libhccl.so failed. ret = %d.", ret);
    return OK;
}

aclnnStatus NnopbaseSetHcomGroup(void *const executor, char *const group)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    CHECK_COND(((NnopbaseExecutor *)executor)->mc2OpCfg.isMc2, ACLNN_ERR_PARAM_INVALID,
               "Nnopbase opType=%s set Hcom group failed, not mc2 op. group = %p.",
               ((NnopbaseExecutor *)executor)->opType, group);
    if ((group == nullptr) || strcmp(group, "") == 0) {
        ((NnopbaseExecutor *)executor)->mc2OpCfg.hcomHandle.push_back(nullptr);
    } else {
        NNOPBASE_ASSERT_OK_RETVAL(NnopbaseSetMc2Tiling(((NnopbaseExecutor *)executor), group));
    }
    return OK;
}

void *NnopbaseGetApiFunc(const char *funcName)
{
    return nnopbase::ApiWrapper::GetInstance().GetFunc(funcName);
}

aclnnStatus NnopbaseSetFormatMatchMode(void *executor, const uint32_t mode)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    ((NnopbaseExecutor *)executor)->formatCheckOption = static_cast<NnopbaseFormatCheckOption>(mode);
    return OK;
}

void NnopbaseSetHcclServerType(void *executor, NnopbaseHcclServerType sType)
{
    NNOPBASE_ASSERT_NOTNULL(executor);
    NnopbaseExecutorSetHcclServerType((NnopbaseExecutor *)executor, sType);
}

void NnopbaseSetHcclServerTypeList(void *executor, NnopbaseHcclServerType *hcclServerTypeList, 
                                   const uint32_t *socSupportList, size_t socSupportListLen)
{
    static const std::map<ge::AscendString, uint32_t> SOC_VERSION_MAP = {
        {"Ascend910", SOC_VERSION_910A},
        {"Ascend910B", SOC_VERSION_910B},
        {"Ascend910_93", SOC_VERSION_910_93},
        {"Ascend910_95", SOC_VERSION_910_95},
        {"Ascend310B", SOC_VERSION_310B},
        {"Ascend310P", SOC_VERSION_310P},
        {"Ascend610Lite", SOC_VERSION_ASCEND610Lite}
    };
    NNOPBASE_ASSERT_NOTNULL(executor);
    NNOPBASE_ASSERT_NOTNULL(hcclServerTypeList);
    NNOPBASE_ASSERT_NOTNULL(socSupportList);
    auto currentSocVersion = op::ToString(op::GetCurrentPlatformInfo().GetSocVersion());
    const auto &iter = SOC_VERSION_MAP.find(currentSocVersion);
    if (iter != SOC_VERSION_MAP.cend()) {
        for (size_t i = 0; i < socSupportListLen; i++) {
            if (socSupportList[i] == iter->second) {
                NnopbaseExecutorSetHcclServerType((NnopbaseExecutor *)executor, hcclServerTypeList[i]);
                return;
            }
        }
    }
}

void NnopbaseSetZeroEleOutputLaunchFlag(void *executor)
{
    NNOPBASE_ASSERT_NOTNULL(executor);
    ((NnopbaseExecutor *)executor)->isZeroEleOutputLaunch = true;
}

void NnopbaseSetMatchArgsFlag(void *executor)
{
    NNOPBASE_ASSERT_NOTNULL(executor);
    ((NnopbaseExecutor *)executor)->matchArgsV2 = true;  
}

bool NnopbaseMatchArgs(void *executor, uint64_t *workspaceLen)
{
    NNOPBASE_ASSERT_NOTNULL_RETVAL(executor);
    NNOPBASE_ASSERT_NOTNULL_RETVAL(workspaceLen);
    NnopbaseExecutor *nnopExecutor = PtrCastTo<NnopbaseExecutor>(executor);
    RecordNnopbaseTime(nnopExecutor, NnopbaseTimeIdx::kGetWsStart);
    nnopbase::NnopbaseGetCoreNum(&nnopExecutor->coreNum.aicNum, &nnopExecutor->coreNum.aivNum);
    NnopbaseUpdatePlatformInfo(nnopExecutor);
    if ((!g_nnopbaseSysCfgParams.enableArgsCache) || op::internal::opProfilingSwitch.recordOpArgFlag) {
        nnopExecutor->ownArgs.enableCache = false;
        OP_LOGI("Op %s does not enable match args cache.", nnopExecutor->opType);
        RecordNnopbaseTime(nnopExecutor, NnopbaseTimeIdx::kMatchCacheStart);
        RecordNnopbaseTime(nnopExecutor, NnopbaseTimeIdx::kMatchCacheEnd);
        return false;
    }
    uint8_t *key = nnopExecutor->ownArgs.inputKey.data();
    key = PtrCastTo<NnopbaseUChar>(
        NnopbaseAppendBinary(key, strlen(nnopExecutor->opType), nnopExecutor->opType, strlen(nnopExecutor->opType)));

    key = NnopbaseAddCoreNumInfo(&nnopExecutor->coreNum, &nnopExecutor->ownArgs);
    uint32_t mc2RankId = nnopbase::utils::ThreadVarContainer::GetCurMc2RankIdInThread();
    OP_LOGD("Current mc2RankId is %u", mc2RankId);
    key = AddMc2RankIdInfoToKey(&mc2RankId, &nnopExecutor->ownArgs);
    nnopExecutor->ownArgs.seed = NnopbaseHashBinary(
        PtrCastTo<NnopbaseUChar>(nnopExecutor->ownArgs.inputKey.data()), nnopExecutor->ownArgs.keyLen);

    if (nnopbase::ArgsPool::GetInstance().MatchArgs(nnopExecutor)) {
        NNOPBASE_ASSERT_OK_RETVAL(NnopbaseUpdateInputAddr(nnopExecutor));
        NNOPBASE_ASSERT_OK_RETVAL(NnopbaseUpdateOutputAddr(&nnopExecutor->args->outputs, &nnopExecutor->ownArgs.outputs));
        NnopbaseCheckHasContiguous(nnopExecutor);
        if (!nnopExecutor->args->inputs.unContiguousTensors.tensors.empty()) {
            OP_LOGI("Executor addr %p, op %s has %zu uncontiguous inputs.",
                nnopExecutor,
                nnopExecutor->opType,
                nnopExecutor->args->inputs.unContiguousTensors.tensors.size());
            return false;
        }
        NnopbaseSetCachedInfo(nnopExecutor);
        *workspaceLen = nnopExecutor->workspaces.length;
        OP_LOGI("Executor addr %p, op %s match args cache successfully, workspaceLen is %lu.",
            nnopExecutor,
            nnopExecutor->opType,
            *workspaceLen);
        NnopbaseExecutorCopyCacheAttr(nnopExecutor);
        return true;
    }

    OP_LOGI("Executor addr %p, op %s not match args cache.", nnopExecutor, nnopExecutor->opType);
    CHECK_COND(NnopbaseAddIoTensors(nnopExecutor) == OK,
        false,
        "Nnopbase opType=%s add io tensors failed.",
        nnopExecutor->opType);
    return false;
}

#ifdef __cplusplus
}
#endif
